{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c3f96bc",
   "metadata": {},
   "source": [
    "# Network analysis of Python libraries and AI-related packages\n",
    "\n",
    "Este notebook constrói uma **rede de dependências entre pacotes Python** e enriquece cada nó com **métricas de vulnerabilidades Snyk**, permitindo comparar:\n",
    "\n",
    "- **Rede completa de pacotes** (todos os packages do CSV)\n",
    "- **Sub-rede apenas de libs usadas para IA/ML** (ex.: `torch`, `transformers`, `mlflow`, `langchain`, `vllm`, etc.)\n",
    "\n",
    "> ⚠️ **Pré-requisitos de arquivos**\n",
    ">\n",
    "> - `VULN_CSV`: CSV com as colunas  \n",
    ">   `package,cve,cwes,severity,first_affected_version,first_affected_date,disclosed_date,mitigation_version,mitigation_date,disclosure_lag_days,time_to_fix_from_first_days,time_to_fix_from_disclosure_days,fix_semver_type`  \n",
    ">   (é o dataset que você já mostrou).\n",
    "> - `DEPS_CSV`: CSV com o grafo de dependências entre pacotes, com **uma linha por aresta**:\n",
    ">   - `source`: pacote que depende (projeto)\n",
    ">   - `target`: pacote requerido (dependência, o “importado”)\n",
    ">\n",
    "> Este notebook **não extrai imports**; ele assume que seu pipeline anterior já gerou esse arquivo de dependências.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14688d0",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Apenas para visualização mais amigável\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.width\", 140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eae9628",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Configurações principais\n",
    "# =========================\n",
    "\n",
    "# Caminhos dos arquivos de entrada\n",
    "VULN_CSV = \"top_pypi_snyk_timeline_20231101_20251101.csv\"   # <-- ajuste para o nome real do seu CSV\n",
    "DEPS_CSV = \"python_dependencies_edges.csv\"     # <-- ajuste para o arquivo de arestas gerado no pipeline\n",
    "\n",
    "# Mapa de severidade para valores numéricos\n",
    "severity_map = {\n",
    "    \"low\": 1,\n",
    "    \"moderate\": 2,\n",
    "    \"medium\": 2,   # caso apareça \"medium\" em algum lugar\n",
    "    \"high\": 3,\n",
    "    \"critical\": 4\n",
    "}\n",
    "\n",
    "# Lista curada de libs voltadas para IA/ML/LLM presentes no dataset\n",
    "AI_LIBS = sorted({\n",
    "    # Núcleo de DL/ML\n",
    "    \"torch\", \"scikit-learn\", \"lightgbm\", \"pytorch-lightning\", \"keras\",\n",
    "    \"paddlepaddle\", \"onnx\", \"xgboost\",\n",
    "    # LLM / RAG / LangChain & família\n",
    "    \"transformers\", \"langchain\", \"langchain-core\", \"langchain-community\",\n",
    "    \"langchain-experimental\", \"llama-index\", \"llama-index-core\",\n",
    "    \"llama-index-cli\", \"vllm\", \"qdrant-client\", \"mlflow\",\n",
    "    # MLOps / pipelines / experiment tracking\n",
    "    \"clearml\", \"feast\", \"sagemaker\", \"kedro\", \"prefect\",\n",
    "    # Interfaces/ferramentas típicas de IA generativa\n",
    "    \"gradio\", \"streamlit\", \"browser-use\", \"ydata-profiling\",\n",
    "    # Outras libs correlatas do seu dataset\n",
    "    \"fastmcp\", \"litellm\", \"skops\", \"lightning\", \"pytorch-lightning\"\n",
    "})\n",
    "\n",
    "print(f\"Total de libs marcadas como IA: {len(AI_LIBS)}\")\n",
    "AI_LIBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ea7a59",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Carregar vulnerabilidades Snyk\n",
    "# =========================\n",
    "\n",
    "vulns = pd.read_csv(VULN_CSV)\n",
    "\n",
    "print(\"Amostra do dataset de vulnerabilidades:\")\n",
    "display(vulns.head())\n",
    "\n",
    "# Parse de datas\n",
    "date_cols = [\"first_affected_date\", \"disclosed_date\", \"mitigation_date\"]\n",
    "for col in date_cols:\n",
    "    if col in vulns.columns:\n",
    "        vulns[col] = pd.to_datetime(vulns[col], errors=\"coerce\")\n",
    "\n",
    "# Garantir colunas numéricas\n",
    "for col in [\"disclosure_lag_days\", \"time_to_fix_from_first_days\", \"time_to_fix_from_disclosure_days\"]:\n",
    "    if col in vulns.columns:\n",
    "        vulns[col] = pd.to_numeric(vulns[col], errors=\"coerce\")\n",
    "\n",
    "# Severidade numérica\n",
    "vulns[\"severity_norm\"] = (\n",
    "    vulns[\"severity\"]\n",
    "    .astype(str)\n",
    "    .str.lower()\n",
    "    .map(severity_map)\n",
    ")\n",
    "\n",
    "print(\"\\nResumo de severidade:\")\n",
    "display(vulns[\"severity\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fba6048",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Agregar atributos por pacote (nó)\n",
    "# =========================\n",
    "\n",
    "agg = (\n",
    "    vulns\n",
    "    .groupby(\"package\")\n",
    "    .agg(\n",
    "        vuln_count=(\"cve\", \"nunique\"),  # número de CVEs distintos\n",
    "        vuln_rows=(\"cve\", \"size\"),      # número de linhas (inclui linhas sem CVE)\n",
    "        max_severity=(\"severity_norm\", \"max\"),\n",
    "        mean_severity=(\"severity_norm\", \"mean\"),\n",
    "        mean_fix_from_disclosure=(\"time_to_fix_from_disclosure_days\", \"mean\"),\n",
    "        mean_fix_from_first=(\"time_to_fix_from_first_days\", \"mean\"),\n",
    "        first_disclosure=(\"disclosed_date\", \"min\"),\n",
    "        last_disclosure=(\"disclosed_date\", \"max\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(\"Atributos agregados por pacote:\")\n",
    "display(agg.head())\n",
    "\n",
    "print(\"\\nTotal de packages distintos com vulnerabilidades:\", len(agg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df07d52a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Carregar arestas de dependências e construir o grafo\n",
    "# =========================\n",
    "\n",
    "deps = pd.read_csv(DEPS_CSV)\n",
    "\n",
    "print(\"Amostra do arquivo de dependências:\")\n",
    "display(deps.head())\n",
    "\n",
    "# Ajuste aqui se suas colunas tiverem outros nomes\n",
    "SRC_COL = \"source\"  # projeto que depende\n",
    "DST_COL = \"target\"  # dependência requerida\n",
    "\n",
    "missing_cols = {SRC_COL, DST_COL} - set(deps.columns)\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"As colunas {missing_cols} não foram encontradas em {DEPS_CSV}. Ajuste SRC_COL/DST_COL.\")\n",
    "\n",
    "# Construir grafo direcionado: source -> target\n",
    "G = nx.DiGraph()\n",
    "\n",
    "for _, row in deps.iterrows():\n",
    "    src = str(row[SRC_COL])\n",
    "    dst = str(row[DST_COL])\n",
    "    if src and dst and src != \"nan\" and dst != \"nan\":\n",
    "        G.add_edge(src, dst)\n",
    "\n",
    "# Garantir que todos os packages vulneráveis apareçam, mesmo que sem arestas\n",
    "for pkg in agg[\"package\"].astype(str):\n",
    "    if pkg not in G:\n",
    "        G.add_node(pkg)\n",
    "\n",
    "print(f\"Grafo criado com {G.number_of_nodes()} nós e {G.number_of_edges()} arestas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8da05a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Atribuir atributos aos nós (do DataFrame 'agg')\n",
    "# =========================\n",
    "\n",
    "attr_dict = (\n",
    "    agg\n",
    "    .set_index(\"package\")\n",
    "    .to_dict(orient=\"index\")\n",
    ")\n",
    "\n",
    "nx.set_node_attributes(G, attr_dict)\n",
    "\n",
    "# Flag de lib IA\n",
    "ai_flags = {pkg: (pkg in AI_LIBS) for pkg in G.nodes()}\n",
    "nx.set_node_attributes(G, ai_flags, \"is_ai_lib\")\n",
    "\n",
    "# Verificar exemplo de nó\n",
    "sample_node = list(G.nodes())[0]\n",
    "print(\"Exemplo de nó com atributos:\")\n",
    "print(sample_node, G.nodes[sample_node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d749571a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Métricas de rede\n",
    "# =========================\n",
    "\n",
    "# Graus\n",
    "degree_dict = dict(G.degree())\n",
    "in_degree_dict = dict(G.in_degree())\n",
    "out_degree_dict = dict(G.out_degree())\n",
    "\n",
    "nx.set_node_attributes(G, degree_dict, \"degree\")\n",
    "nx.set_node_attributes(G, in_degree_dict, \"in_degree\")\n",
    "nx.set_node_attributes(G, out_degree_dict, \"out_degree\")\n",
    "\n",
    "# Betweenness centrality (pode ser custoso em grafos muito grandes)\n",
    "print(\"Calculando betweenness centrality (pode demorar um pouco)...\")\n",
    "betweenness_dict = nx.betweenness_centrality(G, normalized=True)\n",
    "nx.set_node_attributes(G, betweenness_dict, \"betweenness\")\n",
    "\n",
    "# Eigenvector centrality (usando versão baseada em álgebra linear)\n",
    "print(\"Calculando eigenvector centrality (usando grafo não direcionado)...\")\n",
    "UG = G.to_undirected()\n",
    "try:\n",
    "    eigenvector_dict = nx.eigenvector_centrality_numpy(UG)\n",
    "except Exception as e:\n",
    "    print(\"Falha ao calcular eigenvector centrality com método numpy:\", e)\n",
    "    eigenvector_dict = {}\n",
    "\n",
    "nx.set_node_attributes(G, eigenvector_dict, \"eigenvector\")\n",
    "\n",
    "# Densidade da rede (não direcionada)\n",
    "density = nx.density(UG)\n",
    "print(f\"\\nDensidade da rede (não direcionada): {density:.6f}\")\n",
    "\n",
    "# Comunidades e modularidade\n",
    "print(\"Calculando comunidades (greedy modularity)...\")\n",
    "from networkx.algorithms import community\n",
    "\n",
    "communities = list(community.greedy_modularity_communities(UG))\n",
    "modularity_value = community.modularity(UG, communities)\n",
    "print(f\"Modularidade (greedy): {modularity_value:.6f}\")\n",
    "print(f\"Número de comunidades detectadas: {len(communities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b20f1e",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Consolidar atributos de nós em um DataFrame\n",
    "# =========================\n",
    "\n",
    "nodes_data = []\n",
    "for node, data in G.nodes(data=True):\n",
    "    row = {\"package\": node}\n",
    "    row.update(data)\n",
    "    nodes_data.append(row)\n",
    "\n",
    "nodes_df = pd.DataFrame(nodes_data)\n",
    "\n",
    "print(\"Amostra do DataFrame de nós:\")\n",
    "display(nodes_df.head())\n",
    "\n",
    "print(\"\\nColunas disponíveis em nodes_df:\")\n",
    "print(nodes_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe61156",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Comparação: rede completa vs libs de IA\n",
    "# =========================\n",
    "\n",
    "nodes_total = nodes_df.copy()\n",
    "nodes_ai = nodes_df[nodes_df[\"is_ai_lib\"] == True].copy()\n",
    "nodes_non_ai = nodes_df[nodes_df[\"is_ai_lib\"] == False].copy()\n",
    "\n",
    "print(f\"Total de nós (todos os packages): {len(nodes_total)}\")\n",
    "print(f\"Total de nós (libs IA): {len(nodes_ai)}\")\n",
    "print(f\"Total de nós (não IA): {len(nodes_non_ai)}\")\n",
    "\n",
    "def describe_metric(df, col):\n",
    "    return df[col].describe().to_frame(name=col)\n",
    "\n",
    "metrics_to_compare = [\"degree\", \"in_degree\", \"out_degree\", \"betweenness\", \"eigenvector\", \"max_severity\", \"mean_fix_from_disclosure\"]\n",
    "\n",
    "summary_total = pd.concat(\n",
    "    [describe_metric(nodes_total, m) for m in metrics_to_compare if m in nodes_total.columns],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "summary_ai = pd.concat(\n",
    "    [describe_metric(nodes_ai, m) for m in metrics_to_compare if m in nodes_ai.columns],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "summary_non_ai = pd.concat(\n",
    "    [describe_metric(nodes_non_ai, m) for m in metrics_to_compare if m in nodes_non_ai.columns],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"\\nResumo das métricas - REDE COMPLETA:\")\n",
    "display(summary_total)\n",
    "\n",
    "print(\"\\nResumo das métricas - LIBS IA:\")\n",
    "display(summary_ai)\n",
    "\n",
    "print(\"\\nResumo das métricas - NÃO IA:\")\n",
    "display(summary_non_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df859f9a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Top nós por centralidade (geral vs IA)\n",
    "# =========================\n",
    "\n",
    "TOP_N = 20\n",
    "\n",
    "def top_by(df, col, label):\n",
    "    if col not in df.columns:\n",
    "        print(f\"Coluna {col} não encontrada.\")\n",
    "        return\n",
    "    print(f\"\\nTop {TOP_N} por {col} - {label}:\")\n",
    "    display(\n",
    "        df[[\"package\", col, \"vuln_count\", \"max_severity\", \"mean_fix_from_disclosure\"]]\n",
    "        .sort_values(col, ascending=False)\n",
    "        .head(TOP_N)\n",
    "    )\n",
    "\n",
    "for metric in [\"degree\", \"betweenness\", \"eigenvector\"]:\n",
    "    top_by(nodes_total, metric, \"Rede completa\")\n",
    "    top_by(nodes_ai, metric, \"Apenas libs IA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbe1d69",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Visualizações simples: distribuição de grau e severidade\n",
    "# =========================\n",
    "\n",
    "plt.figure()\n",
    "nodes_total[\"degree\"].hist(bins=30)\n",
    "plt.title(\"Distribuição do grau - rede completa\")\n",
    "plt.xlabel(\"degree\")\n",
    "plt.ylabel(\"frequência\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "nodes_ai[\"degree\"].hist(bins=15)\n",
    "plt.title(\"Distribuição do grau - libs IA\")\n",
    "plt.xlabel(\"degree\")\n",
    "plt.ylabel(\"frequência\")\n",
    "plt.show()\n",
    "\n",
    "# Comparação de severidade máxima (1=low .. 4=critical)\n",
    "plt.figure()\n",
    "nodes_total[\"max_severity\"].hist(bins=[0.5,1.5,2.5,3.5,4.5])\n",
    "plt.title(\"Severidade máxima por pacote - rede completa\")\n",
    "plt.xlabel(\"max_severity (1=low, 4=critical)\")\n",
    "plt.ylabel(\"freq\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "nodes_ai[\"max_severity\"].hist(bins=[0.5,1.5,2.5,3.5,4.5])\n",
    "plt.title(\"Severidade máxima por pacote - libs IA\")\n",
    "plt.xlabel(\"max_severity (1=low, 4=critical)\")\n",
    "plt.ylabel(\"freq\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e306e6a0",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Comunidades contendo libs IA (visão rápida)\n",
    "# =========================\n",
    "\n",
    "# Mapeia cada nó para o ID da comunidade (0..N-1)\n",
    "node_to_comm = {}\n",
    "for i, comm in enumerate(communities):\n",
    "    for node in comm:\n",
    "        node_to_comm[node] = i\n",
    "\n",
    "nodes_df[\"community_id\"] = nodes_df[\"package\"].map(node_to_comm)\n",
    "\n",
    "ai_communities = (\n",
    "    nodes_df[nodes_df[\"is_ai_lib\"] == True]\n",
    "    .groupby(\"community_id\")\n",
    "    .size()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "print(\"Comunidades (community_id) com mais libs IA:\")\n",
    "display(ai_communities.head(10))\n",
    "\n",
    "print(\"\\nExemplo de comunidade com libs IA (top 1):\")\n",
    "if not ai_communities.empty:\n",
    "    top_comm_id = ai_communities.index[0]\n",
    "    display(nodes_df[nodes_df[\"community_id\"] == top_comm_id][[\"package\", \"is_ai_lib\", \"degree\", \"max_severity\"]]\n",
    "            .sort_values(\"is_ai_lib\", ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
