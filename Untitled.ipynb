{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d7035de-f56e-420c-ad64-9a8794b04af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty AI 1-hop graph\n"
     ]
    }
   ],
   "source": [
    "# AI + 1-hop with ALL nodes colored by severity; AI bigger with bold border\n",
    "import os, numpy as np\n",
    "import pandas as pd, networkx as nx, matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "os.makedirs('outputs/plots', exist_ok=True)\n",
    "\n",
    "# Force rebuild of globals if they exist\n",
    "for v in ['DG_all','UG_all','pkg_sev','color_map']:\n",
    "    if v in globals():\n",
    "        del globals()[v]\n",
    "\n",
    "# Helper to normalize package/node names\n",
    "def normalize_pkg(name: str) -> str:\n",
    "    return str(name).strip().lower().replace('_', '-')\n",
    "\n",
    "try:\n",
    "    DG_all, UG_all, pkg_sev, color_map\n",
    "except NameError:\n",
    "    # 1) Build graph from dependency edges (not from timeline)\n",
    "    edges = pd.read_csv('python_dependencies_edges.csv')\n",
    "    edges['source'] = edges['source'].astype(str).map(normalize_pkg)\n",
    "    edges['target'] = edges['target'].astype(str).map(normalize_pkg)\n",
    "    DG_all = nx.DiGraph()\n",
    "    DG_all.add_edges_from(edges[['source','target']].itertuples(index=False, name=None))\n",
    "    UG_all = DG_all.to_undirected()\n",
    "\n",
    "    # 2) Build package -> severity map from MERGED timeline\n",
    "    pkg_sev = {}\n",
    "    vuln_path = 'outputs/summaries/top_pypi_snyk_timeline_merged.csv'\n",
    "    if not os.path.exists(vuln_path):\n",
    "        vuln_path = 'outputs/top_pypi_snyk_timeline_20231101_20251101.csv'\n",
    "    if os.path.exists(vuln_path):\n",
    "        vulns = pd.read_csv(vuln_path)\n",
    "        if 'package' in vulns.columns:\n",
    "            vulns['package'] = vulns['package'].astype(str).map(normalize_pkg)\n",
    "        if 'severity' in vulns.columns:\n",
    "            vulns['severity'] = vulns['severity'].astype(str).str.lower().fillna('unknown')\n",
    "            sev_rank = {'low':1,'medium':2,'moderate':2,'high':3,'critical':4}\n",
    "            vulns['sev_rank'] = vulns['severity'].map(lambda s: sev_rank.get(s,0))\n",
    "            agg = vulns.groupby('package', as_index=False)['sev_rank'].max()\n",
    "            inv = {v:k for k,v in sev_rank.items()}\n",
    "            agg['severity_max'] = agg['sev_rank'].map(lambda r: inv.get(r,'unknown'))\n",
    "            pkg_sev = dict(zip(agg['package'], agg['severity_max']))\n",
    "    color_map = {'critical':'#d73027','high':'#fc8d59','medium':'#fee08b','moderate':'#fee08b','low':'#91bfdb','unknown':'#bdbdbd'}\n",
    "\n",
    "# Ensure AI_LIBS exists\n",
    "try:\n",
    "    AI_LIBS\n",
    "except NameError:\n",
    "    AI_LIBS = []\n",
    "\n",
    "# AI nodes + 1 hop neighbors\n",
    "ai_nodes = {normalize_pkg(p) for p in AI_LIBS if normalize_pkg(p) in UG_all}\n",
    "ai_focus = set(ai_nodes)\n",
    "for n in list(ai_nodes):\n",
    "    if n in UG_all:\n",
    "        ai_focus.update(UG_all.neighbors(n))\n",
    "\n",
    "H = UG_all.subgraph(ai_focus).copy()\n",
    "if H.number_of_nodes() == 0:\n",
    "    print('Empty AI 1-hop graph')\n",
    "else:\n",
    "    # Largest connected component for readability\n",
    "    comps = sorted(nx.connected_components(H), key=len, reverse=True)\n",
    "    H = H.subgraph(comps[0]).copy()\n",
    "\n",
    "    # Spring layout\n",
    "    k = 1/np.sqrt(max(H.number_of_nodes(),1))\n",
    "    pos = nx.spring_layout(H, k=k*3, iterations=450, seed=23)\n",
    "\n",
    "    # Sizes by in-degree (influence)\n",
    "    indeg = dict(DG_all.in_degree(H.nodes()))\n",
    "    base = np.array([max(1, indeg.get(n,0)) for n in H.nodes()])\n",
    "    p95 = np.percentile(base, 95) if np.any(base) else 1.0\n",
    "    sizes = (base/p95 * 500).clip(10, 900)\n",
    "\n",
    "    # AI highlight\n",
    "    ai_set = set(ai_nodes) & set(H.nodes())\n",
    "    sizes_ai  = [(max(1, indeg.get(n,0))/p95 * 900) for n in ai_set]\n",
    "    sizes_ai  = np.clip(sizes_ai, 40, 1400)\n",
    "\n",
    "    # Colors by severity (normalize names to match pkg_sev)\n",
    "    def sev(n):\n",
    "        s = str(pkg_sev.get(normalize_pkg(n), 'unknown')).lower()\n",
    "        return 'medium' if s == 'moderate' else s\n",
    "\n",
    "    # Draw\n",
    "    fig, ax = plt.subplots(1,1, figsize=(18,14))\n",
    "    nx.draw_networkx_edges(H, pos, ax=ax, width=0.35, alpha=0.14, edge_color='#9e9e9e')\n",
    "\n",
    "    ctx_nodes = [n for n in H.nodes() if n not in ai_set]\n",
    "    # Fast lookup for sizes\n",
    "    idx = {n:i for i,n in enumerate(H.nodes())}\n",
    "    ctx_sizes  = [sizes[idx[n]] for n in ctx_nodes]\n",
    "    ctx_colors = [color_map.get(sev(n), color_map['unknown']) for n in ctx_nodes]\n",
    "    nx.draw_networkx_nodes(H, pos, nodelist=ctx_nodes, node_size=ctx_sizes, node_color=ctx_colors,\n",
    "                           edgecolors='#666666', linewidths=0.25, alpha=0.95, ax=ax)\n",
    "\n",
    "    nx.draw_networkx_nodes(H, pos, nodelist=list(ai_set), node_size=sizes_ai,\n",
    "                           node_color=[color_map.get(sev(n), color_map['unknown']) for n in ai_set],\n",
    "                           edgecolors='black', linewidths=0.9, alpha=0.98, ax=ax)\n",
    "\n",
    "    # Label main AI hubs\n",
    "    ai_hubs = sorted([(n, indeg.get(n,0)) for n in ai_set], key=lambda x: x[1], reverse=True)[:25]\n",
    "    labels = {n:n for n,_ in ai_hubs}\n",
    "    nx.draw_networkx_labels(H, pos, labels=labels, font_size=9, font_weight='bold', ax=ax)\n",
    "\n",
    "    legend_handles = [\n",
    "        Patch(color=color_map['critical'], label='critical'),\n",
    "        Patch(color=color_map['high'],     label='high'),\n",
    "        Patch(color=color_map['medium'],   label='medium'),\n",
    "        Patch(color=color_map['low'],      label='low'),\n",
    "        Patch(facecolor='white', edgecolor='black', label='AI (bold border)'),\n",
    "    ]\n",
    "    ax.legend(handles=legend_handles, title='Legend', frameon=False, loc='lower left')\n",
    "\n",
    "    subtitle = f\"Nodes={H.number_of_nodes()}  Edges={H.number_of_edges()}  AI nodes={len(ai_set)}\"\n",
    "    ax.set_title(f\"AI packages â€” 1-hop (all dependencies colored by severity)\\n{subtitle}\", fontsize=14, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('outputs/plots/dependency_severity_ai_1hop_colored.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a3f239a-1441-496f-8bef-91e3c8b6c5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19529990-750b-420a-942c-5524a130010c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
